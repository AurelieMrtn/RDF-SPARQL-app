{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from rdflib import Graph, Literal, Namespace, URIRef\n",
    "from rdflib.namespace import DCTERMS, RDF, RDFS, SKOS, XSD\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"movies_metadata.csv\")\n",
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov = movies.loc[:,[\"id\", \"genres\", \"original_language\", \"production_countries\", \"title\",\"release_date\"]]\n",
    "mov = mov.dropna()\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov['release_date'] = pd.to_datetime(mov['release_date'])\n",
    "\n",
    "# Sélectionner uniquement l'année\n",
    "mov['year'] = mov['release_date'].dt.year\n",
    "mov = mov.drop('release_date', axis=1)\n",
    "\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langcodes\n",
    "\n",
    "# Liste des codes de langue\n",
    "lang_codes = mov['original_language']\n",
    "\n",
    "l = []\n",
    "\n",
    "# Boucle pour obtenir le nom complet de chaque langue\n",
    "for i in lang_codes:\n",
    "    lang_name = langcodes.Language.get(i).language_name()\n",
    "    l.append(lang_name)\n",
    "\n",
    "mov['language'] = l\n",
    "mov = mov.drop('original_language', axis=1)\n",
    "\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "serie_liste = mov['genres']\n",
    "genres = []\n",
    "\n",
    "# Convertir la chaîne en une liste Python\n",
    "ma_liste = [ast.literal_eval(element) for element in serie_liste]\n",
    "\n",
    "# Ne garder que les genres\n",
    "for item in ma_liste:\n",
    "    \n",
    "    lst = []\n",
    "    for el in item:\n",
    "        objet = json.loads(str(el).replace(\"'\", \"\\\"\"))\n",
    "        nom = objet[\"name\"]\n",
    "        lst.append(nom)\n",
    "    genres.append(lst)\n",
    "        \n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exists = set([\"Thriller\", \"Crime\", \"Action\", \"Drama\", \"Comedy\"])\n",
    "authorized = []\n",
    "\n",
    "for item in genres:\n",
    "    \n",
    "    lst = []\n",
    "    for el in item:\n",
    "        if el in exists:\n",
    "            lst.append(el)\n",
    "    authorized.append(lst)\n",
    "    \n",
    "authorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov['genres'] = authorized\n",
    "mov = mov.drop(mov[mov['genres'].apply(len) == 0].index)\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "mov['production_countries'] = mov['production_countries'].apply(lambda x: ast.literal_eval(x))\n",
    "mov['production_countries'] = mov['production_countries'].apply(lambda x: x[0]['name'] if len(x) > 0 else None)\n",
    "\n",
    "mov = mov.dropna(subset=['production_countries'])\n",
    "\n",
    "mov = mov.drop_duplicates(subset='id')\n",
    "mov = mov.drop_duplicates(subset='title')\n",
    "mov = mov.rename(columns={'production_countries': 'country'})\n",
    "mov['id'] = mov['id'].astype('int64')\n",
    "mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"credits.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_actors(cast):\n",
    "    cast_list = ast.literal_eval(cast)\n",
    "    return [(actor['name'], actor['gender'], 0) for actor in cast_list]\n",
    "\n",
    "def extract_crew(crew, job):\n",
    "    crew_list = ast.literal_eval(crew)\n",
    "    return [(member['name'], member['gender'], 0) for member in crew_list if member['job'] == job]\n",
    "\n",
    "\n",
    "df['actors'] = df['cast'].apply(extract_actors)\n",
    "df['director'] = [extract_crew(row['crew'], 'Director') for _, row in df.iterrows()]\n",
    "df['writers'] = [extract_crew(row['crew'], 'Writer') for _, row in df.iterrows()]\n",
    "\n",
    "\n",
    "# drop the original \"cast\" and \"crew\" columns\n",
    "df.drop(['cast', 'crew'], axis=1, inplace=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(mov, df, left_on='id', right_on='id')\n",
    "light_df = merged_df.sample(n=1000)\n",
    "light_df.to_csv('mov.csv', index=False)\n",
    "\n",
    "light_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from owlready2 import *\n",
    "import pandas as pd\n",
    "\n",
    "# Load the ontology\n",
    "onto = get_ontology(\"Ontology1.owl\").load()\n",
    "\n",
    "# Define the classes in the ontology\n",
    "df = pd.read_csv('mov.csv')\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x))\n",
    "df['actors'] = df['actors'].apply(lambda x: ast.literal_eval(x))\n",
    "df['director'] = df['director'].apply(lambda x: ast.literal_eval(x))\n",
    "df['writers'] = df['writers'].apply(lambda x: ast.literal_eval(x))\n",
    "# Loop through the rows of the CSV file and create instances of the Movie class\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "\n",
    "    ##print(row)\n",
    "    # Create instances of the Genre class\n",
    "    genres = []\n",
    "    for g in row['genres']:\n",
    "        match g:\n",
    "            case 'Action':\n",
    "                genres.append(onto.Action)\n",
    "            case 'Drama':\n",
    "                genres.append(onto.Drama)\n",
    "            case 'Comedy':\n",
    "                genres.append(onto.Comedy)\n",
    "            case 'Thriller':\n",
    "                genres.append(onto.Thriller)\n",
    "            case 'Crime':\n",
    "                genres.append(onto.Crime)\n",
    "            case _:\n",
    "                print(index)\n",
    "                pass\n",
    "    # Create instances of the Person class\n",
    "    directors = [onto.Director(name=n.strip(), Sexe=[str(s)], Age=[a]) for (n,s,a) in row['director']]\n",
    "    writers = [onto.Writer(name=n.strip(), Sexe=[str(s)], Age=[a]) for (n,s,a) in row['writers']]\n",
    "    actors = [onto.Actor(name=n.strip(), Sexe=[str(s)], Age=[a]) for (n,s,a) in row['actors']]\n",
    "    # Create an instance of the Movie class and add the directors, writers, actors, genres, and other properties\n",
    "    try:\n",
    "        movie = onto.Movie(name=row['title'].strip())  \n",
    "        movie.hasGenre = genres\n",
    "        movie.Year = [row['year']]\n",
    "        movie.Country = [row['country']]\n",
    "        movie.Language = [row['language']]\n",
    "        movie.hasDirector = directors\n",
    "        movie.hasWriter = writers\n",
    "        movie.hasActor = actors\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    \n",
    "    # Add the instance to the ontology\n",
    "    print(index)\n",
    "\n",
    "onto.save(file=\"Imported1.owl\", format = \"rdfxml\")\n",
    "    #print(\"Number of instances after:\", len(list(onto.individuals())))\n",
    "\n",
    "list(default_world.sparql(\"\"\"SELECT (COUNT(?x) AS ?nb){ ?x a owl:Class . FILTER(ISIRI(?x)) }\"\"\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?Inst WHERE{\n",
    "    ?Inst rdf:type Ontology1:Actor\n",
    "    } GROUP BY ?Inst\n",
    "\"\"\"\n",
    "\n",
    "filename = \"Query1.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?movies ?director WHERE{\n",
    "    ?movies Ontology1:hasGenre Ontology1:Thriller .\n",
    "    OPTIONAL {?director Ontology1:isDirectorOf ?movies}\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "filename = \"Query2.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?movies WHERE{\n",
    "    ?movies Ontology1:hasGenre Ontology1:Thriller .\n",
    "    ?movies Ontology1:hasGenre Ontology1:Crime\n",
    "    }\n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query3.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?actors WHERE{\n",
    "    ?actors Ontology1:Age ?age .\n",
    "    ?actors rdf:type Ontology1:Actor .\n",
    "    FILTER(?age>51)\n",
    "    }\n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query4.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?movies ?actor ?year WHERE{\n",
    "    ?movies Ontology1:hasGenre Ontology1:Comedy .\n",
    "    OPTIONAL{?movies Ontology1:Year ?year} .\n",
    "    OPTIONAL {?movies Ontology1:hasActor ?actor}\n",
    "    }\n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query6.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT ?movies ?year ?Country WHERE{ \n",
    "    ?movies Ontology1:Year ?year .\n",
    "    ?movies Ontology1:Country ?Country .\n",
    "    {?movies Ontology1:hasGenre Ontology1:Comedy . ?movies Ontology1:hasGenre Ontology1:Crime .}\n",
    "    UNION\n",
    "    {?movies Ontology1:Language Ontology1:English .}\n",
    "\n",
    "    }\n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query7.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "     CONSTRUCT {?movie Ontology1:Countries ?countries .\n",
    "                ?movie Ontology1:Language ?lang}\n",
    "     WHERE{?movie Ontology1:Country ?countries .\n",
    "            ?movie Ontology1:Language ?lang}\n",
    "    \n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query8.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SPARQL query\n",
    "import rdflib as rdf\n",
    "\n",
    "Ontology1 = rdf.Namespace(\"http://www.semanticweb.org/movie-ontology#\")\n",
    "\n",
    "query = \"\"\"\n",
    "    ASK{ ?movie Ontology1:Language \"English\" .\n",
    "        ?movie Ontology1:Country \"France\"} \n",
    "    \n",
    "\"\"\"\n",
    "graph = default_world.as_rdflib_graph()\n",
    "\n",
    "graph.bind(\"Ontology1\", Ontology1)\n",
    "result = list(graph.query_owlready(query))\n",
    "\n",
    "filename = \"Query9.txt\"\n",
    "\n",
    "# Execute the query and convert the result to a list\n",
    "#result = list(default_world.sparql(query))\n",
    "\n",
    "# Open the file for writing with UTF-8 encoding\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate over the list and write each item to the file\n",
    "    for item in result:\n",
    "        f.write(str(item))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
